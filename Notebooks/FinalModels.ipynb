{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "%cd /gdrive/My Drive/[2023-2024] AN2DL/Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix randomness and hide warnings\n",
    "seed = 65\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "os.environ['MPLCONFIGDIR'] = os.getcwd()+'/configs/'\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(seed)\n",
    "\n",
    "import logging\n",
    "\n",
    "import random\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as tfk\n",
    "from tensorflow.keras import layers as tfkl\n",
    "tf.autograph.set_verbosity(0)\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "tf.random.set_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import other libraries\n",
    "#library for computer vision\n",
    "import cv2\n",
    "#from tensorflow.keras.applications.mobilenet import preprocess_input #errore messo qua non serve a nulla in questo notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data upload and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.load('/kaggle/input/publicdata/public_data.npz', allow_pickle=True)\n",
    "#Load imaages from dataset\n",
    "images_not_normalized = data['data']\n",
    "labels_strings= data['labels']\n",
    "label_map = {\"healthy\": 0, \"unhealthy\": 1}\n",
    "labels = np.vectorize(label_map.get)(labels_strings)\n",
    "print(images_not_normalized.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize images\n",
    "images=[]\n",
    "for img in images_not_normalized:\n",
    "  img=(img/255).astype(np.float32)\n",
    "  images.append(img)\n",
    "\n",
    "images= np.array(images)\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATASET CLEANING!\n",
    "#We remove all the outliers manually found while inspecting the dataset\n",
    "indices= np.array([ 58, 95, 137, 138, 171, 207, 338,  412, 434, 486, 506, 529, 571, 599, 622, 658, 692, 701, 723, 725, 753, 779, 783, 827, 840, 880, 898, 901, 961, 971, 974, 989,\n",
    " 1028, 1044, 1064, 1065, 1101, 1149, 1172, 1190, 1191, 1265, 1268, 1280, 1333, 1384, 1443, 1466, 1483, 1528, 1541, 1554, 1594, 1609, 1630, 1651, 1690, 1697, 1752, 1757, 1759,\n",
    " 1806, 1828, 1866, 1903, 1938, 1939, 1977, 1981, 1988, 2022, 2081, 2090, 2150, 2191, 2192, 2198, 2261, 2311, 2328, 2348, 2380, 2426, 2435, 2451, 2453, 2487, 2496, 2515, 2564, 2581,\n",
    " 2593, 2596, 2663, 2665, 2676, 2727, 2734, 2736, 2755, 2779, 2796, 2800, 2830, 2831, 2839, 2864, 2866, 2889, 2913, 2929, 2937, 3033, 3049, 3055, 3086, 3105, 3108, 3144, 3155, 3286,\n",
    " 3376, 3410, 3436, 3451, 3488, 3490, 3572, 3583, 3666, 3688, 3700, 3740, 3770, 3800, 3801, 3802, 3806, 3811, 3821, 3835, 3862, 3885, 3896, 3899, 3904, 3927, 3931, 3946, 3950, 3964,\n",
    " 3988, 3989, 4049, 4055, 4097, 4100, 4118, 4144, 4150, 4282, 4310, 4314, 4316, 4368, 4411, 4475, 4476, 4503, 4507, 4557, 4605, 4618, 4694, 4719, 4735, 4740, 4766, 4779, 4837, 4848,\n",
    " 4857, 4860, 4883, 4897, 4903, 4907, 4927, 5048, 5080, 5082, 5121, 5143, 5165, 5171])\n",
    "print(indices.shape)\n",
    "mask = np.ones(len(images), dtype=bool)\n",
    "mask[indices]=False\n",
    "images=images[mask]\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding \n",
    "labels = tfk.utils.to_categorical(labels,len(np.unique(labels))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, labels, random_state=seed, test_size=.25, stratify=np.argmax(labels,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print shapes of the datasets\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input shape, output shape, batch size, and number of epochs\n",
    "input_shape = X_train.shape[1:]\n",
    "output_shape = y_train.shape[1:]\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "# Print input shape, batch size, and number of epochs\n",
    "print(f\"Input Shape: {input_shape}, Output Shape: {output_shape}, Batch Size: {batch_size}, Epochs: {epochs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation through kerasCV layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We are augmenting the data by applying  cutmix, mixup, and mixup on cutmix. Hence, as final training set we obtain the union between: Original training set, Cutmix set, Mixup set, mixup on cutmix set</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install keras_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_augment=keras_cv.layers.RandAugment(\n",
    "    (0,1),\n",
    "    augmentations_per_image=3,\n",
    "    magnitude=0.25,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_randaugmented=rand_augment(X_train)\n",
    "y_train_randaugmented=y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutmix = keras_cv.layers.CutMix(10)\n",
    "output = cutmix({\"images\": X_train, \"labels\": y_train})\n",
    "X_train_cutmix=output['images']\n",
    "y_train_cutmix=output['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixup = keras_cv.layers.MixUp(10)\n",
    "output = mixup({\"images\": X_train, \"labels\": y_train})\n",
    "X_train_mixup=output['images']\n",
    "y_train_mixup=output['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixup = keras_cv.layers.MixUp(42)\n",
    "output = mixup({\"images\": X_train_cutmix, \"labels\": y_train_cutmix})\n",
    "X_train_mixoncut=output['images']\n",
    "y_train_mixoncut=output['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the augmentations \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "imgs_to_show=100\n",
    "startToShowFrom=0\n",
    "\n",
    "fig, axes = plt.subplots(10, 10, figsize=(30, 20))\n",
    "\n",
    "# Reshape the axes to a 1D array for easier indexing\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Display the first 10 images with labels\n",
    "for i in range(imgs_to_show):\n",
    "    axes[i].imshow(X_train_randaugmented[i+startToShowFrom])\n",
    "    axes[i].set_title(f'l: {y_train_randaugmented[i+startToShowFrom]}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "# Ensure tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the grid of images with labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_to_show=100\n",
    "startToShowFrom=0\n",
    "\n",
    "fig, axes = plt.subplots(10, 10, figsize=(30, 20))\n",
    "\n",
    "# Reshape the axes to a 1D array for easier indexing\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Display the first 10 images with labels\n",
    "for i in range(imgs_to_show):\n",
    "    axes[i].imshow(X_train_cutmix[i+startToShowFrom])\n",
    "    axes[i].set_title(f'l: {y_train_cutmix[i+startToShowFrom]}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "# Ensure tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the grid of images with labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_to_show=100\n",
    "startToShowFrom=0\n",
    "\n",
    "fig, axes = plt.subplots(10, 10, figsize=(30, 20))\n",
    "\n",
    "# Reshape the axes to a 1D array for easier indexing\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Display the first 10 images with labels\n",
    "for i in range(imgs_to_show):\n",
    "    axes[i].imshow(X_train_mixup[i+startToShowFrom])\n",
    "    axes[i].set_title(f'l: {y_train_mixup[i+startToShowFrom]}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "# Ensure tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the grid of images with labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_to_show=100\n",
    "startToShowFrom=0\n",
    "\n",
    "fig, axes = plt.subplots(10, 10, figsize=(30, 20))\n",
    "\n",
    "# Reshape the axes to a 1D array for easier indexing\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Display the first 10 images with labels\n",
    "for i in range(imgs_to_show):\n",
    "    axes[i].imshow(X_train_mixoncut[i+startToShowFrom])\n",
    "    axes[i].set_title(f'l: {y_train_mixoncut[i+startToShowFrom]}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "# Ensure tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the grid of images with labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_mixup.shape)\n",
    "print(X_train_cutmix.shape)\n",
    "print(X_train.shape)\n",
    "print(X_train_randaugmented.shape)\n",
    "print(X_train_mixoncut.shape)\n",
    "print('AAA')\n",
    "print(y_train_mixup.shape)\n",
    "print(y_train_cutmix.shape)\n",
    "print(y_train.shape)\n",
    "print(y_train_randaugmented.shape)\n",
    "print(y_train_mixoncut.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unite and shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate all the augmentation to obtain a unique training set\n",
    "X_train_augmented=np.concatenate((X_train_randaugmented, X_train_cutmix, X_train_mixup, X_train_mixoncut,X_train), axis=0)\n",
    "y_train_augmented=np.concatenate((y_train_randaugmented, y_train_cutmix, y_train_mixup, y_train_mixoncut,y_train), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function will distribute the samples uniformly over dataset\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly shuffling the concatenated dataset\n",
    "X_train_augmented_shuffled, y_train_augmented_shuffled = unison_shuffled_copies(X_train_augmented, y_train_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_to_show=100\n",
    "startToShowFrom=0\n",
    "\n",
    "fig, axes = plt.subplots(10, 10, figsize=(30, 20))\n",
    "\n",
    "# Reshape the axes to a 1D array for easier indexing\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Display the first 10 images with labels\n",
    "for i in range(imgs_to_show):\n",
    "    axes[i].imshow(X_train_augmented_shuffled[i+startToShowFrom])\n",
    "    axes[i].set_title(f'l: {y_train_augmented_shuffled[i+startToShowFrom]}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "# Ensure tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the grid of images with labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_augmented_shuffled.shape)\n",
    "print(y_train_augmented_shuffled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean memory\n",
    "del X_train_cutmix\n",
    "del y_train_cutmix\n",
    "del X_train_mixup\n",
    "del y_train_mixup\n",
    "del X_train_augmented\n",
    "del y_train_augmented\n",
    "del X_train_mixoncut\n",
    "del y_train_mixoncut\n",
    "del X_train\n",
    "del y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning and Fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConvneXtLarge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load pretrained ConvNexTLarge from keras.appilcations</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convnext = tf.keras.applications.ConvNeXtLarge(\n",
    "    model_name=\"convnext_large\",\n",
    "    include_top=False,\n",
    "    include_preprocessing=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=input_shape,\n",
    "    pooling=\"avg\",\n",
    "    classifier_activation=\"softmax\",\n",
    ")\n",
    "tfk.utils.plot_model(convnext, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convnext.trainable = False #We freeze the weights of the CNN\n",
    "tf.random.set_seed(seed)\n",
    "#A layer that applies additional augmentation on the data during training\n",
    "preprocessing = tf.keras.Sequential([ \n",
    "    tfkl.RandomFlip(\"vertical\"),\n",
    "    tfkl.RandomFlip(\"horizontal\"),\n",
    "    tfkl.RandomRotation(0.5),\n",
    "    tfkl.RandomZoom(0.1)\n",
    "], name='preprocessing')\n",
    "\n",
    "\n",
    "inputs = tfk.Input(shape=(96, 96, 3))\n",
    "preprocessing = preprocessing(inputs)\n",
    "x = convnext(preprocessing)\n",
    "x = tfkl.Dense(units=256, kernel_initializer=tfk.initializers.HeUniform(seed=seed), name='HiddenDense1')(x)\n",
    "x = tfkl.Activation('relu', name='HiddenActivation1')(x)\n",
    "x = tfkl.BatchNormalization()(x)\n",
    "x = tfkl.Dense(units=128, kernel_initializer=tfk.initializers.HeUniform(seed=seed), name='HiddenDense2')(x)\n",
    "x = tfkl.Activation('relu', name='HiddenActivation2')(x)\n",
    "x = tfkl.BatchNormalization()(x)\n",
    "# Add a Dense layer with 2 units and softmax activation as the classifier\n",
    "outputs = tfkl.Dense(2, activation='softmax')(x)\n",
    "\n",
    "convnext_model = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n",
    "\n",
    "convnext_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.AdamW(1e-4, weight_decay=5e-4), metrics=['accuracy'])\n",
    "convnext_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks=[\n",
    "    tfk.callbacks.EarlyStopping(monitor='val_accuracy', patience=35, restore_best_weights=True, mode='max'),\n",
    "    tfk.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\", factor=0.1, patience=25, min_lr=1e-5, mode='max')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "convnext_history = convnext_model.fit(\n",
    "    x = X_train_augmented_shuffled*255.0, # We need to apply the preprocessing thought for the MobileNetV2 network\n",
    "    y = y_train_augmented_shuffled,\n",
    "    batch_size=100,\n",
    "    epochs = 500,\n",
    "    validation_data = (X_val*255.0, y_val), # We need to apply the preprocessing thought for the MobileNetV2 network\n",
    "    callbacks = callbacks\n",
    ").history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convnext_model.save('ConvNextLargeAdvAugTL.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del convnext_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(convnext_history['loss'], alpha=.3, color='#ff7f0e', linestyle='--')\n",
    "plt.plot(convnext_history['val_loss'], label='ConvNextLTF', alpha=.8, color='#ff7f0e')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Categorical Crossentropy')\n",
    "plt.grid(alpha=.3)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(convnext_history['accuracy'], alpha=.3, color='#ff7f0e', linestyle='--')\n",
    "plt.plot(convnext_history['val_accuracy'], label='ConvNextLTF', alpha=.8, color='#ff7f0e')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Accuracy')\n",
    "plt.grid(alpha=.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>We now reload the model in order to do fine tuning</h3>\n",
    "<p>In order to do so, we need to manually pass the LayerScale custom class of the model in the scope when we load the model</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerScale(tfkl.Layer):\n",
    "    \"\"\"Layer scale module.\n",
    "\n",
    "    References:\n",
    "\n",
    "    - https://arxiv.org/abs/2103.17239\n",
    "\n",
    "    Args:\n",
    "        init_values (float): Initial value for layer scale. Should be within\n",
    "            [0, 1].\n",
    "        projection_dim (int): Projection dimensionality.\n",
    "\n",
    "    Returns:\n",
    "        Tensor multiplied to the scale.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, init_values, projection_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.init_values = init_values\n",
    "        self.projection_dim = projection_dim\n",
    "\n",
    "    def build(self, _):\n",
    "        self.gamma = self.add_weight(\n",
    "            shape=(self.projection_dim,),\n",
    "            initializer=tfk.initializers.Constant(self.init_values),\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        return x * self.gamma\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"init_values\": self.init_values,\n",
    "                \"projection_dim\": self.projection_dim,\n",
    "            }\n",
    "        )\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the model\n",
    "with tfk.utils.custom_object_scope({'LayerScale': LayerScale}):\n",
    "    ft_model = tf.keras.models.load_model('/kaggle/input/convnextlargerandaugtl/kaggle/working/ConvNextLargeAdvAugTL.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We unfreeze the entire CNN\n",
    "ft_model.get_layer('convnext_large').trainable = True\n",
    "for i, layer in enumerate(ft_model.get_layer('convnext_large').layers):\n",
    "   print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recompile the model\n",
    "ft_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.AdamW(1e-5,weight_decay=5e-4), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks=[\n",
    "    tfk.callbacks.EarlyStopping(monitor='val_accuracy', patience=35, restore_best_weights=True, mode='max'),\n",
    "    tfk.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\", factor=0.1, patience=25, min_lr=1e-6, mode='max')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "ft_history = ft_model.fit(\n",
    "    x = X_train_augmented_shuffled*255.0, # We need to apply the preprocessing thought for the MobileNetV2 network\n",
    "    y = y_train_augmented_shuffled,\n",
    "    batch_size = 64,\n",
    "    epochs = 1000,\n",
    "    validation_data = (X_val*255.0, y_val), # We need to apply the preprocessing thought for the MobileNetV2 network\n",
    "    callbacks = callbacks\n",
    ").history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(ft_history['loss'], alpha=.3, color='#ff7f0e', linestyle='--')\n",
    "plt.plot(ft_history['val_loss'], label='ConvNextLFT', alpha=.8, color='#ff7f0e')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Categorical Crossentropy')\n",
    "plt.grid(alpha=.3)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(ft_history['accuracy'], alpha=.3, color='#ff7f0e', linestyle='--')\n",
    "plt.plot(ft_history['val_accuracy'], label='ConvNextLFT', alpha=.8, color='#ff7f0e')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Accuracy')\n",
    "plt.grid(alpha=.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model.save('ConvNextLargeAdvAugFT.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConvNextXL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "convnext = tf.keras.applications.ConvNeXtXLarge(\n",
    "    include_top=False,\n",
    "    include_preprocessing=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=input_shape,\n",
    "    pooling=\"avg\",\n",
    "    classifier_activation=\"softmax\",\n",
    "    classes = 2,\n",
    ")\n",
    "#tfk.utils.plot_model(convnext, show_shapes=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "convnext.trainable = False #Freeze the entire CNN \n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "#First layer for augmentation during the training phase\n",
    "preprocessing = tf.keras.Sequential([\n",
    "    tfkl.RandomFlip(\"vertical\"),\n",
    "    tfkl.RandomFlip(\"horizontal\"),\n",
    "    tfkl.RandomRotation(0.5),\n",
    "    tfkl.RandomZoom(0.1),\n",
    "    tfkl.RandomBrightness(factor=(-0.3,0.3), value_range=(0, 255), seed=seed)\n",
    "], name='preprocessing')\n",
    "\n",
    "\n",
    "inputs = tfk.Input(shape=(96, 96, 3))\n",
    "preprocessing = preprocessing(inputs)\n",
    "x = convnext(preprocessing)\n",
    "x = tfkl.Dense(units=256, kernel_initializer=tfk.initializers.HeUniform(seed=seed), name='HiddenDense1')(x)\n",
    "x = tfkl.Activation('relu', name='HiddenActivation1')(x)\n",
    "x = tfkl.BatchNormalization()(x)\n",
    "x = tfkl.Dense(units=128, kernel_initializer=tfk.initializers.HeUniform(seed=seed), name='HiddenDense2')(x)\n",
    "x = tfkl.Activation('relu', name='HiddenActivation2')(x)\n",
    "x = tfkl.BatchNormalization()(x)\n",
    "# Add a Dense layer with 2 units and softmax activation as the classifier\n",
    "outputs = tfkl.Dense(2, activation='softmax')(x)\n",
    "\n",
    "convnext_model = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n",
    "\n",
    "convnext_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.AdamW(1e-4, weight_decay=5e-4), metrics=['accuracy'])\n",
    "convnext_model.summary()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "callbacks=[\n",
    "    tfk.callbacks.EarlyStopping(monitor='val_accuracy', patience=25, restore_best_weights=True, mode='max'),\n",
    "    tfk.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\", factor=0.1, patience=15, min_lr=1e-5, mode='max')\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train the model\n",
    "convnext_history = convnext_model.fit(\n",
    "    x = X_train_augmented_shuffled*255.0, # We need to apply the preprocessing thought for the MobileNetV2 network\n",
    "    y = y_train_augmented_shuffled,\n",
    "    batch_size=100,\n",
    "    epochs = 500,\n",
    "    validation_data = (X_val*255.0, y_val), # We need to apply the preprocessing thought for the MobileNetV2 network\n",
    "    callbacks = callbacks\n",
    ").history\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convnext_model.save('ConvNextLAdvAugTF_more.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del convnext_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Fine tuning</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerScale(tfkl.Layer):\n",
    "    \"\"\"Layer scale module.\n",
    "\n",
    "    References:\n",
    "\n",
    "    - https://arxiv.org/abs/2103.17239\n",
    "\n",
    "    Args:\n",
    "        init_values (float): Initial value for layer scale. Should be within\n",
    "            [0, 1].\n",
    "        projection_dim (int): Projection dimensionality.\n",
    "\n",
    "    Returns:\n",
    "        Tensor multiplied to the scale.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, init_values, projection_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.init_values = init_values\n",
    "        self.projection_dim = projection_dim\n",
    "\n",
    "    def build(self, _):\n",
    "        self.gamma = self.add_weight(\n",
    "            shape=(self.projection_dim,),\n",
    "            initializer=tfk.initializers.Constant(self.init_values),\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        return x * self.gamma\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"init_values\": self.init_values,\n",
    "                \"projection_dim\": self.projection_dim,\n",
    "            }\n",
    "        )\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reload model\n",
    "with tfk.utils.custom_object_scope({'LayerScale': LayerScale}):\n",
    "            ft_model = tf.keras.models.load_model('/kaggle/input/convenxtxl/ConvNextXLAdvAugTF.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = convnext_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unfreeze the entire CNN\n",
    "ft_model.get_layer('convnext_xlarge').trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freeze Normalization layers\n",
    "for i, layer in enumerate(ft_model.get_layer('convnext_xlarge').layers):\n",
    "  if 'layernorm' in layer.name:\n",
    "    layer.trainable=False\n",
    "  print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.AdamW(1e-5,weight_decay=5e-4), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks=[\n",
    "    tfk.callbacks.EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True, mode='max'),\n",
    "    tfk.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\", factor=0.1, patience=10, min_lr=1e-6, mode='max')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "ft_history = ft_model.fit(\n",
    "    x = X_train_augmented_shuffled*255.0, # We need to apply the preprocessing thought for the MobileNetV2 network\n",
    "    y = y_train_augmented_shuffled,\n",
    "    batch_size = 32,\n",
    "    epochs = 1000,\n",
    "    validation_data = (X_val*255.0, y_val), # We need to apply the preprocessing thought for the MobileNetV2 network\n",
    "    callbacks = callbacks\n",
    ").history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(ft_history['loss'], alpha=.3, color='#ff7f0e', linestyle='--')\n",
    "plt.plot(ft_history['val_loss'], label='EfficientNet+MLP', alpha=.8, color='#ff7f0e')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Categorical Crossentropy')\n",
    "plt.grid(alpha=.3)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(ft_history['accuracy'], alpha=.3, color='#ff7f0e', linestyle='--')\n",
    "plt.plot(ft_history['val_accuracy'], label='EfficientNet+MLP', alpha=.8, color='#ff7f0e')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Accuracy')\n",
    "plt.grid(alpha=.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model.save('ConvNextXLAdvAugFT_more.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConvNextLarge with additional augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation through kerasCV layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>this time we are applying additional augmentation. In particular we are using ColorDegeneration, FourierMix</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install keras_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_augment=keras_cv.layers.RandAugment(\n",
    "    (0,1),\n",
    "    augmentations_per_image=3,\n",
    "    magnitude=0.25,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_randaugmented=rand_augment(X_train)\n",
    "y_train_randaugmented=y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutmix = keras_cv.layers.CutMix(10)\n",
    "output = cutmix({\"images\": X_train, \"labels\": y_train})\n",
    "X_train_cutmix=output['images']\n",
    "y_train_cutmix=output['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixup = keras_cv.layers.MixUp(10)\n",
    "output = mixup({\"images\": X_train, \"labels\": y_train})\n",
    "X_train_mixup=output['images']\n",
    "y_train_mixup=output['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixup = keras_cv.layers.MixUp(42)\n",
    "output = mixup({\"images\": X_train_cutmix, \"labels\": y_train_cutmix})\n",
    "X_train_mixoncut=output['images']\n",
    "y_train_mixoncut=output['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_degeneration = keras_cv.layers.RandomColorDegeneration((0.3,0.75), seed=seed)\n",
    "output = color_degeneration({\"images\": X_train, \"labels\": y_train})\n",
    "X_train_degeneration=output['images']\n",
    "y_train_degeneration=output['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourier_mix = keras_cv.layers.FourierMix(alpha=0.5, decay_power=3, seed=seed)\n",
    "output = fourier_mix({\"images\": X_train, \"labels\": y_train})\n",
    "X_train_fourier=output['images']\n",
    "y_train_fourier=output['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the augmentations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_to_show=100\n",
    "startToShowFrom=0\n",
    "\n",
    "fig, axes = plt.subplots(10, 10, figsize=(30, 20))\n",
    "\n",
    "# Reshape the axes to a 1D array for easier indexing\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Display the first 10 images with labels\n",
    "for i in range(imgs_to_show):\n",
    "    axes[i].imshow(X_train_randaugmented[i+startToShowFrom])\n",
    "    axes[i].set_title(f'l: {y_train_randaugmented[i+startToShowFrom]}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "# Ensure tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the grid of images with labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_to_show=100\n",
    "startToShowFrom=0\n",
    "\n",
    "fig, axes = plt.subplots(10, 10, figsize=(30, 20))\n",
    "\n",
    "# Reshape the axes to a 1D array for easier indexing\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Display the first 10 images with labels\n",
    "for i in range(imgs_to_show):\n",
    "    axes[i].imshow(X_train_cutmix[i+startToShowFrom])\n",
    "    axes[i].set_title(f'l: {y_train_cutmix[i+startToShowFrom]}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "# Ensure tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the grid of images with labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_to_show=100\n",
    "startToShowFrom=0\n",
    "\n",
    "fig, axes = plt.subplots(10, 10, figsize=(30, 20))\n",
    "\n",
    "# Reshape the axes to a 1D array for easier indexing\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Display the first 10 images with labels\n",
    "for i in range(imgs_to_show):\n",
    "    axes[i].imshow(X_train_mixup[i+startToShowFrom])\n",
    "    axes[i].set_title(f'l: {y_train_mixup[i+startToShowFrom]}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "# Ensure tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the grid of images with labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_to_show=100\n",
    "startToShowFrom=0\n",
    "\n",
    "fig, axes = plt.subplots(10, 10, figsize=(30, 20))\n",
    "\n",
    "# Reshape the axes to a 1D array for easier indexing\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Display the first 10 images with labels\n",
    "for i in range(imgs_to_show):\n",
    "    axes[i].imshow(X_train_mixoncut[i+startToShowFrom])\n",
    "    axes[i].set_title(f'l: {y_train_mixoncut[i+startToShowFrom]}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "# Ensure tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the grid of images with labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_to_show=100\n",
    "startToShowFrom=0\n",
    "\n",
    "fig, axes = plt.subplots(10, 10, figsize=(30, 20))\n",
    "\n",
    "# Reshape the axes to a 1D array for easier indexing\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Display the first 10 images with labels\n",
    "for i in range(imgs_to_show):\n",
    "    axes[i].imshow(X_train_degeneration[i+startToShowFrom])\n",
    "    axes[i].set_title(f'l: {y_train_degeneration[i+startToShowFrom]}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "# Ensure tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the grid of images with labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_to_show=100\n",
    "startToShowFrom=0\n",
    "\n",
    "fig, axes = plt.subplots(10, 10, figsize=(30, 20))\n",
    "\n",
    "# Reshape the axes to a 1D array for easier indexing\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Display the first 10 images with labels\n",
    "for i in range(imgs_to_show):\n",
    "    axes[i].imshow(X_train_fourier[i+startToShowFrom])\n",
    "    axes[i].set_title(f'l: {y_train_fourier[i+startToShowFrom]}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "# Ensure tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the grid of images with labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_mixup.shape)\n",
    "print(X_train_cutmix.shape)\n",
    "print(X_train.shape)\n",
    "print(X_train_randaugmented.shape)\n",
    "print(X_train_mixoncut.shape)\n",
    "print('AAA')\n",
    "print(y_train_mixup.shape)\n",
    "print(y_train_cutmix.shape)\n",
    "print(y_train.shape)\n",
    "print(y_train_randaugmented.shape)\n",
    "print(y_train_mixoncut.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unite augmentation to obtain single training set\n",
    "X_train_augmented=np.concatenate((X_train_fourier,X_train_degeneration,X_train_randaugmented, X_train_cutmix, X_train_mixup, X_train_mixoncut,X_train), axis=0)\n",
    "y_train_augmented=np.concatenate((y_train_fourier,y_train_degeneration,y_train_randaugmented, y_train_cutmix, y_train_mixup, y_train_mixoncut,y_train), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unite and shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function will distribute the samples uniformly over dataset\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly shuffling the concatenated dataset\n",
    "X_train_augmented_shuffled, y_train_augmented_shuffled = unison_shuffled_copies(X_train_augmented, y_train_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_to_show=100\n",
    "startToShowFrom=0\n",
    "\n",
    "fig, axes = plt.subplots(10, 10, figsize=(30, 20))\n",
    "\n",
    "# Reshape the axes to a 1D array for easier indexing\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Display the first 10 images with labels\n",
    "for i in range(imgs_to_show):\n",
    "    axes[i].imshow(X_train_augmented_shuffled[i+startToShowFrom])\n",
    "    axes[i].set_title(f'l: {y_train_augmented_shuffled[i+startToShowFrom]}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "# Ensure tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the grid of images with labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_augmented_shuffled.shape)\n",
    "print(y_train_augmented_shuffled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train_cutmix\n",
    "del y_train_cutmix\n",
    "del X_train_mixup\n",
    "del y_train_mixup\n",
    "del X_train_augmented\n",
    "del y_train_augmented\n",
    "del X_train_mixoncut\n",
    "del y_train_mixoncut\n",
    "del X_train\n",
    "del y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning and fine tuning of ConvNextLarge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the pretrained model\n",
    "convnext = tf.keras.applications.ConvNeXtLarge(\n",
    "    include_top=False,\n",
    "    include_preprocessing=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=input_shape,\n",
    "    pooling=\"avg\",\n",
    "    classifier_activation=\"softmax\",\n",
    "    classes = 2,\n",
    ")\n",
    "#tfk.utils.plot_model(convnext, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convnext.trainable = False\n",
    "tf.random.set_seed(seed)\n",
    "#Additional augmentation layer (this time we added the RandomBrightness layers)\n",
    "preprocessing = tf.keras.Sequential([ \n",
    "    tfkl.RandomFlip(\"vertical\"),\n",
    "    tfkl.RandomFlip(\"horizontal\"),\n",
    "    tfkl.RandomRotation(0.5),\n",
    "    tfkl.RandomZoom(0.1),\n",
    "    tfkl.RandomBrightness(factor=(-0.3,0.3), value_range=(0, 255), seed=seed)\n",
    "], name='preprocessing')\n",
    "\n",
    "\n",
    "inputs = tfk.Input(shape=(96, 96, 3))\n",
    "preprocessing = preprocessing(inputs)\n",
    "x = convnext(preprocessing)\n",
    "x = tfkl.Dense(units=256, kernel_initializer=tfk.initializers.HeUniform(seed=seed), name='HiddenDense1')(x)\n",
    "x = tfkl.Activation('relu', name='HiddenActivation1')(x)\n",
    "x = tfkl.BatchNormalization()(x)\n",
    "x = tfkl.Dense(units=128, kernel_initializer=tfk.initializers.HeUniform(seed=seed), name='HiddenDense2')(x)\n",
    "x = tfkl.Activation('relu', name='HiddenActivation2')(x)\n",
    "x = tfkl.BatchNormalization()(x)\n",
    "# Add a Dense layer with 2 units and softmax activation as the classifier\n",
    "outputs = tfkl.Dense(2, activation='softmax')(x)\n",
    "\n",
    "convnext_model = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n",
    "\n",
    "convnext_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.AdamW(1e-4, weight_decay=5e-4), metrics=['accuracy'])\n",
    "convnext_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks=[\n",
    "    tfk.callbacks.EarlyStopping(monitor='val_accuracy', patience=25, restore_best_weights=True, mode='max'),\n",
    "    tfk.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\", factor=0.1, patience=15, min_lr=1e-5, mode='max')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "convnext_history = convnext_model.fit(\n",
    "    x = X_train_augmented_shuffled*255.0, \n",
    "    y = y_train_augmented_shuffled,\n",
    "    batch_size=100,\n",
    "    epochs = 500,\n",
    "    validation_data = (X_val*255.0, y_val), \n",
    "    callbacks = callbacks\n",
    ").history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convnext_model.save('ConvNextLAdvAugTF_more.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del convnext_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerScale(tfkl.Layer):\n",
    "    \"\"\"Layer scale module.\n",
    "\n",
    "    References:\n",
    "\n",
    "    - https://arxiv.org/abs/2103.17239\n",
    "\n",
    "    Args:\n",
    "        init_values (float): Initial value for layer scale. Should be within\n",
    "            [0, 1].\n",
    "        projection_dim (int): Projection dimensionality.\n",
    "\n",
    "    Returns:\n",
    "        Tensor multiplied to the scale.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, init_values, projection_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.init_values = init_values\n",
    "        self.projection_dim = projection_dim\n",
    "\n",
    "    def build(self, _):\n",
    "        self.gamma = self.add_weight(\n",
    "            shape=(self.projection_dim,),\n",
    "            initializer=tfk.initializers.Constant(self.init_values),\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        return x * self.gamma\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"init_values\": self.init_values,\n",
    "                \"projection_dim\": self.projection_dim,\n",
    "            }\n",
    "        )\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reload the model\n",
    "with tfk.utils.custom_object_scope({'LayerScale': LayerScale}):\n",
    "            ft_model = tf.keras.models.load_model('/kaggle/input/convenxtxl/ConvNextXLAdvAugTF.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unfreeze the entire CNN\n",
    "ft_model.get_layer('convnext_large').trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freeze only the LayerNorm Layers\n",
    "for i, layer in enumerate(ft_model.get_layer('convnext_large').layers):\n",
    "  if 'layernorm' in layer.name:\n",
    "    layer.trainable=False\n",
    "  print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recompile the model\n",
    "ft_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.AdamW(1e-5,weight_decay=5e-4), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks=[\n",
    "    tfk.callbacks.EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True, mode='max'),\n",
    "    tfk.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\", factor=0.1, patience=10, min_lr=1e-6, mode='max')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "ft_history = ft_model.fit(\n",
    "    x = X_train_augmented_shuffled*255.0, \n",
    "    y = y_train_augmented_shuffled,\n",
    "    batch_size = 32,\n",
    "    epochs = 1000,\n",
    "    validation_data = (X_val*255.0, y_val), \n",
    "    callbacks = callbacks\n",
    ").history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(ft_history['loss'], alpha=.3, color='#ff7f0e', linestyle='--')\n",
    "plt.plot(ft_history['val_loss'], label='ConvNextL_AdvAug+', alpha=.8, color='#ff7f0e')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Categorical Crossentropy')\n",
    "plt.grid(alpha=.3)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(ft_history['accuracy'], alpha=.3, color='#ff7f0e', linestyle='--')\n",
    "plt.plot(ft_history['val_accuracy'], label='ConvNextL_AdvAug+', alpha=.8, color='#ff7f0e')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Accuracy')\n",
    "plt.grid(alpha=.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model.save('ConvNextLAdvAugFT_more.h5')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
