{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "6NYuSmhl2F8W",
        "WsMaikrh2KWu",
        "XjalPQod2VN-",
        "UHGzCxJA2rIn",
        "H62m3DAf25jD",
        "IyxCo44g3yqB",
        "Y9Ve05ne5VHC",
        "QXC2gC2k41pG",
        "_LW4gIAH41ut"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to google drive"
      ],
      "metadata": {
        "id": "6NYuSmhl2F8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/My Drive/[2023-2024] AN2DL/Homework 1"
      ],
      "metadata": {
        "id": "Zbr_zx6H2IqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import librieries and set parameters"
      ],
      "metadata": {
        "id": "WsMaikrh2KWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix randomness and hide warnings\n",
        "seed = 80\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "os.environ['MPLCONFIGDIR'] = os.getcwd()+'/configs/'\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=Warning)\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(seed)\n",
        "\n",
        "import logging\n",
        "\n",
        "import random\n",
        "random.seed(seed)"
      ],
      "metadata": {
        "id": "8zt8cHcf2NnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras as tfk\n",
        "from tensorflow.keras import layers as tfkl\n",
        "tf.autograph.set_verbosity(0)\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "7hBpEcZ72PUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import other libraries\n",
        "#library for computer vision\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "5JU2bvwe2QnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data upload and preprocessing"
      ],
      "metadata": {
        "id": "XjalPQod2VN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Conditional check for unzipping\n",
        "unzip = False\n",
        "\n",
        "if unzip:\n",
        "    !unzip public_data.zip\n"
      ],
      "metadata": {
        "id": "-3Lv8_5h3JEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=np.load('public_data.npz', allow_pickle=True)\n",
        "#Load the images not normalized\n",
        "images_not_normalized = data['data']\n",
        "labels_strings= data['labels']\n",
        "label_map = {\"healthy\": 0, \"unhealthy\": 1}\n",
        "labels = np.vectorize(label_map.get)(labels_strings)\n",
        "print(images_not_normalized.shape)\n",
        "print(labels.shape)"
      ],
      "metadata": {
        "id": "8lBd_i0R2YmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalize images\n",
        "images=[]\n",
        "for img in images_not_normalized:\n",
        "  img=(img/255).astype(np.float32)\n",
        "  images.append(img)\n",
        "\n",
        "images= np.array(images)\n",
        "print(img)"
      ],
      "metadata": {
        "id": "n8Rgi-fx2aPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DATASET CLEANING!\n",
        "#We remove all the outliers, manually found while inspecting the dataset\n",
        "indices= np.array([ 58, 95, 137, 138, 171, 207, 338,  412, 434, 486, 506, 529, 571, 599, 622, 658, 692, 701, 723, 725, 753, 779, 783, 827, 840, 880, 898, 901, 961, 971, 974, 989,\n",
        " 1028, 1044, 1064, 1065, 1101, 1149, 1172, 1190, 1191, 1265, 1268, 1280, 1333, 1384, 1443, 1466, 1483, 1528, 1541, 1554, 1594, 1609, 1630, 1651, 1690, 1697, 1752, 1757, 1759,\n",
        " 1806, 1828, 1866, 1903, 1938, 1939, 1977, 1981, 1988, 2022, 2081, 2090, 2150, 2191, 2192, 2198, 2261, 2311, 2328, 2348, 2380, 2426, 2435, 2451, 2453, 2487, 2496, 2515, 2564, 2581,\n",
        " 2593, 2596, 2663, 2665, 2676, 2727, 2734, 2736, 2755, 2779, 2796, 2800, 2830, 2831, 2839, 2864, 2866, 2889, 2913, 2929, 2937, 3033, 3049, 3055, 3086, 3105, 3108, 3144, 3155, 3286,\n",
        " 3376, 3410, 3436, 3451, 3488, 3490, 3572, 3583, 3666, 3688, 3700, 3740, 3770, 3800, 3801, 3802, 3806, 3811, 3821, 3835, 3862, 3885, 3896, 3899, 3904, 3927, 3931, 3946, 3950, 3964,\n",
        " 3988, 3989, 4049, 4055, 4097, 4100, 4118, 4144, 4150, 4282, 4310, 4314, 4316, 4368, 4411, 4475, 4476, 4503, 4507, 4557, 4605, 4618, 4694, 4719, 4735, 4740, 4766, 4779, 4837, 4848,\n",
        " 4857, 4860, 4883, 4897, 4903, 4907, 4927, 5048, 5080, 5082, 5121, 5143, 5165, 5171])\n",
        "print(indices.shape)\n",
        "mask = np.ones(len(images), dtype=bool)\n",
        "mask[indices]=False\n",
        "images = images[mask]\n",
        "labels = labels[mask]\n",
        "print(images.shape)"
      ],
      "metadata": {
        "id": "GXgu-5ke2ct9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class imbalance"
      ],
      "metadata": {
        "id": "UHGzCxJA2rIn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We noticed by counting the elements class-wise an imbalance between the positive and the negative class."
      ],
      "metadata": {
        "id": "m41FLNX42ucM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count0=0\n",
        "count1=0\n",
        "for i in range(labels.shape[0]):\n",
        "  if labels[i]==0:\n",
        "    count0=count0+1\n",
        "  else:\n",
        "    count1=count1+1\n",
        "\n",
        "print(count0)\n",
        "print(count1)\n",
        "\n",
        "#class 1 is much less rapresented!!"
      ],
      "metadata": {
        "id": "DPmYFkEH22Lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First attempt - Dataset balancing trough targeted data augmentation"
      ],
      "metadata": {
        "id": "H62m3DAf25jD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count0=0\n",
        "count1=0\n",
        "for i in range(labels.shape[0]):\n",
        "  if labels[i]==0:\n",
        "    count0=count0+1\n",
        "  else:\n",
        "    count1=count1+1\n",
        "\n",
        "print(count0)\n",
        "print(count1)\n",
        "\n",
        "#class 1 is much less rapresented!!"
      ],
      "metadata": {
        "id": "1O1gpB7J3nA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define data augmentation settings\n",
        "#We tried to reason on which transformations to apply in order to avoid the network learning wrong features\n",
        "#For example, we didn't use blurring! It would teach the network that blurry images -> class 1! It wouldn't generalize.\n",
        "data_augmentation = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Augment only class 1\n",
        "images_augmented = []\n",
        "labels_augmented = []\n",
        "\n",
        "for i in range(len(images)):\n",
        "    if labels[i]==1 and count0>count1:\n",
        "      augmented_sample=data_augmentation.random_transform(images[i])\n",
        "      images_augmented.append(augmented_sample)\n",
        "      labels_augmented.append(1)\n",
        "      count1=count1+1\n",
        "    images_augmented.append(images[i])\n",
        "    labels_augmented.append(labels[i])\n",
        "\n",
        "images_augmented = np.array(images_augmented)\n",
        "labels_augmented = np.array(labels_augmented)\n",
        "\n",
        "# Now we have x_train_augmented and y_train_augmented, where data augmentation is only applied to samples belonging to class 1\n",
        "\n",
        "print(images_augmented.shape)\n",
        "print(labels_augmented.shape)\n"
      ],
      "metadata": {
        "id": "QmknNH9X3p74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count0=0\n",
        "count1=0\n",
        "for i in range(labels_augmented.shape[0]):\n",
        "  if labels_augmented[i]==0:\n",
        "    count0=count0+1\n",
        "  else:\n",
        "    count1=count1+1\n",
        "\n",
        "print(count0)\n",
        "print(count1)\n",
        "\n",
        "#Now ther are equal!!"
      ],
      "metadata": {
        "id": "9z1wVJcJ3rH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fix labels, split samples"
      ],
      "metadata": {
        "id": "IyxCo44g3yqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_augmented=np.expand_dims(labels_augmented,axis=1)\n",
        "print(labels_augmented.shape)"
      ],
      "metadata": {
        "id": "ykkn5QZK4NGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #one hot encoding\n",
        "labels_augmented = tfk.utils.to_categorical(labels_augmented,len(np.unique(labels_augmented)))"
      ],
      "metadata": {
        "id": "aN1LJ1CB4OZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split data into training and validation\n",
        "X_train_augmented, X_val_augmented, y_train_augmented, y_val_augmented = train_test_split(images_augmented, labels_augmented, random_state=seed, test_size=.25, stratify=np.argmax(labels_augmented,axis=1))"
      ],
      "metadata": {
        "id": "Wi-PSWXf4RFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print shapes of the datasets\n",
        "print(f\"X_train shape: {X_train_augmented.shape}, y_train shape: {y_train_augmented.shape}\")\n",
        "print(f\"X_val shape: {X_val_augmented.shape}, y_val shape: {y_val_augmented.shape}\")"
      ],
      "metadata": {
        "id": "tPXtISKQ4S1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input shape, output shape, batch size, and number of epochs\n",
        "input_augmented_shape = X_train_augmented.shape[1:]\n",
        "output_augmented_shape = y_train_augmented.shape[1:]\n",
        "batch_size = 32\n",
        "epochs = 100\n",
        "\n",
        "# Print input shape, batch size, and number of epochs\n",
        "print(f\"Input Shape: {input_augmented_shape}, Output Shape: {output_augmented_shape}, Batch Size: {batch_size}, Epochs: {epochs}\")"
      ],
      "metadata": {
        "id": "0vEa3QTN4VWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train EffNetV2S"
      ],
      "metadata": {
        "id": "Y9Ve05ne5VHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained EfficientNetV2-S model\n",
        "effnetv2s_model = tf.keras.applications.EfficientNetV2S(\n",
        "    include_top=False, #don't load the fully connected aprt\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=input_augmented_shape,\n",
        "    pooling='avg',\n",
        "    include_preprocessing=True,\n",
        ")\n",
        "effnetv2s_model.trainable = False"
      ],
      "metadata": {
        "id": "EKBo0wj-5qdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#A layer that applies the augmentations\n",
        "preprocessing = tf.keras.Sequential([\n",
        "    tfkl.RandomFlip(\"vertical\"),\n",
        "    tfkl.RandomFlip(\"horizontal\"),\n",
        "    tfkl.RandomRotation(0.5),\n",
        "    tfkl.RandomZoom(0.1)\n",
        "], name='preprocessing')\n",
        "\n",
        "inputs = tfk.Input(shape=input_augmented_shape)\n",
        "x=preprocessing(inputs)\n",
        "x = effnetv2s_model(x)\n",
        "# Add the first Dense layer with 256 neurons and ReLU activation\n",
        "x = tfkl.Dense(256, activation='relu')(x)\n",
        "x = tfkl.BatchNormalization()(x)\n",
        "# Add the second Dense layer with 128 neurons and ReLU activation\n",
        "x = tfkl.Dense(128, activation='relu')(x)\n",
        "x = tfkl.BatchNormalization()(x)\n",
        "\n",
        "# Add the final Dense layer with 2 units and softmax activation as the classifier\n",
        "outputs = tfkl.Dense(2, activation='softmax')(x)\n",
        "\n",
        "# Create a Model connecting input and output\n",
        "model = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n",
        "\n",
        "# Compile the model with Categorical Cross-Entropy loss and Adam optimizer\n",
        "model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.AdamW(1e-4, weight_decay=5e-4), metrics=['accuracy'])\n",
        "\n",
        "# Display model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "zTvDKFrE4YfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks=[\n",
        "    tfk.callbacks.EarlyStopping(monitor='val_accuracy', patience=25, restore_best_weights=True, mode='max'),\n",
        "    tfk.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\", factor=0.1, patience=20, min_lr=1e-5, mode='max')\n",
        "]"
      ],
      "metadata": {
        "id": "_BuJuclE4Z9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "effnetv2s_history = model.fit(\n",
        "    x = preprocess_input(X_train_augmented*255.0), #Effnet expects input in range 0-255\n",
        "    y = y_train_augmented,\n",
        "    batch_size = 32,\n",
        "    epochs = 1000,\n",
        "    validation_data = (preprocess_input(X_val_augmented*255.0), y_val_augmented), # Same for the validation set\n",
        "    callbacks = callbacks\n",
        ").history"
      ],
      "metadata": {
        "id": "rbGNUT6t4bNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.plot(effnetv2s_history['loss'], alpha=.3, color='#ff7f0e', linestyle='--')\n",
        "plt.plot(effnetv2s_history['val_loss'], label='EffnetV2S', alpha=.8, color='#ff7f0e')\n",
        "plt.legend(loc='upper left')\n",
        "plt.title('Categorical Crossentropy')\n",
        "plt.grid(alpha=.3)\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.plot(effnetv2s_history['accuracy'], alpha=.3, color='#ff7f0e', linestyle='--')\n",
        "plt.plot(effnetv2s_history['val_accuracy'], label='EffnetV2S', alpha=.8, color='#ff7f0e')\n",
        "plt.legend(loc='upper left')\n",
        "plt.title('Accuracy')\n",
        "plt.grid(alpha=.3)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3NAQNJMd4csP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('EffNetTargetedAugmentation_TL')"
      ],
      "metadata": {
        "id": "EDso81SX4hLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ft_modelS = tfk.models.load_model('EffNetTargetedAugmentation_TL')"
      ],
      "metadata": {
        "id": "UcSyiEwD8Ho6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#In the way efficient net works, we need not to unfreeze the batch normalization layers\n",
        "ft_modelS.get_layer('efficientnetv2-s').trainable = True\n",
        "for i, layer in enumerate(ft_modelS.get_layer('efficientnetv2-s').layers):\n",
        "  if 'bn' in layer.name:\n",
        "    layer.trainable=False\n",
        "  print(i, layer.name, layer.trainable)"
      ],
      "metadata": {
        "id": "D2XnVIKl8OLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We decided to freeze up to the 200-th layer\n",
        "N = 200\n",
        "for i, layer in enumerate(ft_modelS.get_layer('efficientnetv2-s').layers[:N]):\n",
        "  layer.trainable=False\n",
        "for i, layer in enumerate(ft_modelS.get_layer('efficientnetv2-s').layers):\n",
        "   print(i, layer.name, layer.trainable)\n",
        "ft_modelS.summary()"
      ],
      "metadata": {
        "id": "bK78Pbns8Tt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ft_modelS.compile(loss=tfk.losses.CategoricalCrossentropy(),\\\n",
        "                  optimizer=tfk.optimizers.AdamW(1e-5,weight_decay=5e-5),\\\n",
        "                  metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "LUpEPwyi8YeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ft_modelS_history = ft_modelS.fit(\n",
        "    x = X_train1*255, # We need to apply the preprocessing thought for the MobileNetV2 network\n",
        "    y = y_train1,\n",
        "    batch_size = 32,\n",
        "    epochs = 1000,\n",
        "    validation_data = (X_val*255, y_val), # We need to apply the preprocessing thought for the MobileNetV2 network\n",
        "    callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=25, restore_best_weights=True),\n",
        "                 tfk.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\", factor=0.1, patience=20, min_lr=1e-6, mode='max')]\n",
        ").history"
      ],
      "metadata": {
        "id": "LBgs0A5N8ciS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ft_modelS.save('EffNetTargetedAugmentation_FT')"
      ],
      "metadata": {
        "id": "XastMHWB8gqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Second attempt - SMOTE"
      ],
      "metadata": {
        "id": "QXC2gC2k41pG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We proceeded in this way:\n",
        "\n",
        "\n",
        "1. Split the data into training and validation;\n",
        "2. Use SMOTE as a class balancer;\n",
        "3. Double check that the training set is now balanced."
      ],
      "metadata": {
        "id": "7aI2lcWL48_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count0=0\n",
        "count1=0\n",
        "for i in range(labels.shape[0]):\n",
        "  if labels[i]==0:\n",
        "    count0=count0+1\n",
        "  else:\n",
        "    count1=count1+1\n",
        "\n",
        "print(count0)\n",
        "print(count1)\n",
        "\n",
        "#class 1 is much less rapresented!!"
      ],
      "metadata": {
        "id": "vB1dFeew44tW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(images, labels, random_state=seed, test_size=.25, stratify=labels)\n",
        "print(X_train.shape[0], X_val.shape[0])"
      ],
      "metadata": {
        "id": "erQ62iu64463"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #One hot encoding\n",
        "y_val = tfk.utils.to_categorical(y_val,len(np.unique(y_val)))"
      ],
      "metadata": {
        "id": "HnX_GRsA45OF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE(random_state=42)\n",
        "X_train = X_train.reshape(X_train.shape[0], 96 * 96 * 3)\n",
        "X_train, y_train = sm.fit_resample(X_train, y_train)\n",
        "X_train = X_train.reshape(X_train.shape[0], 96, 96, 3)\n",
        "count0=0\n",
        "for i in range(y_train.shape[0]):\n",
        "  if y_train[i] == 0:\n",
        "    count0+=1\n",
        "print(count0, y_train.shape[0]-count0)"
      ],
      "metadata": {
        "id": "0Gpo7zuK45fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #One hot encoding\n",
        "y_train = tfk.utils.to_categorical(y_train,len(np.unique(y_train)))\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "id": "s71fmI8i5EtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspect the new images produced"
      ],
      "metadata": {
        "id": "5d32TAW55Kta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imgs_to_show=100\n",
        "startToShowFrom=3000\n",
        "\n",
        "fig, axes = plt.subplots(10, 10, figsize=(30, 20))\n",
        "\n",
        "# Reshape the axes to a 1D array for easier indexing\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i in range(imgs_to_show):\n",
        "    axes[i].imshow(X_train[i+startToShowFrom])\n",
        "    axes[i].set_title(f'i: {y_train[i + startToShowFrom]}')\n",
        "    axes[i].axis('off')\n",
        "\n",
        "# Ensure tight layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the grid of images with labels\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FipfvHwX5E6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = X_train.shape[1:]\n",
        "output_shape = y_train.shape[1:]\n",
        "batch_size = 32\n",
        "epochs = 100\n",
        "\n",
        "# Print input shape, batch size, and number of epochs\n",
        "print(f\"Input Shape: {input_shape}, Output Shape: {output_shape}, Batch Size: {batch_size}, Epochs: {epochs}\")"
      ],
      "metadata": {
        "id": "NetxnkGO6CVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train EffNetV2S"
      ],
      "metadata": {
        "id": "_LW4gIAH41ut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "effnet_s = tf.keras.applications.EfficientNetV2S(\n",
        "    include_top=False, #Don't import fully connected layers\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=(96, 96, 3),\n",
        "    pooling=\"avg\",\n",
        "    classifier_activation=\"softmax\",\n",
        "    include_preprocessing=True,\n",
        ")\n",
        "tfk.utils.plot_model(effnet_s, show_shapes=True)"
      ],
      "metadata": {
        "id": "QrUl68lu6AZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "effnet_s.trainable = False\n",
        "tf.random.set_seed(seed)\n",
        "#A layer that applies the data augmentation\n",
        "preprocessing = tf.keras.Sequential([\n",
        "    tfkl.RandomFlip(\"vertical\"),\n",
        "    tfkl.RandomFlip(\"horizontal\"),\n",
        "    tfkl.RandomRotation(0.5),\n",
        "    tfkl.RandomZoom(0.3)\n",
        "], name='preprocessing')\n",
        "\n",
        "\n",
        "inputs = tfk.Input(shape=(96, 96, 3))\n",
        "preprocessing = preprocessing(inputs)\n",
        "x = effnet_s(preprocessing)\n",
        "x = tfkl.Dense(units=256, kernel_initializer=tfk.initializers.HeUniform(seed=seed), name='HiddenDense1')(x)\n",
        "x = tfkl.Activation('relu', name='HiddenActivation1')(x)\n",
        "x = tfkl.BatchNormalization()(x)\n",
        "x = tfkl.Dense(units=128, kernel_initializer=tfk.initializers.HeUniform(seed=seed), name='HiddenDense2')(x)\n",
        "x = tfkl.Activation('relu', name='HiddenActivation2')(x)\n",
        "x = tfkl.BatchNormalization()(x)\n",
        "# Add a Dense layer with 2 units and softmax activation as the classifier\n",
        "outputs = tfkl.Dense(2, activation='softmax')(x)\n",
        "\n",
        "eff_modelS = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n",
        "\n",
        "eff_modelS.compile(loss=tfk.losses.CategoricalCrossentropy(),\\\n",
        "                  optimizer=tfk.optimizers.AdamW(1e-4,weight_decay=5e-4),\\\n",
        "                  metrics=['accuracy'])\n",
        "eff_modelS.summary()"
      ],
      "metadata": {
        "id": "vG-_uPIZ6Dl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "eff_S_history = eff_modelS.fit(\n",
        "    x = X_train*255, # EfficientNet expects inputs in range 0.255\n",
        "    y = y_train,\n",
        "    batch_size = 32,\n",
        "    epochs = 1000,\n",
        "    validation_data = (X_val*255, y_val), # Same for the validation set\n",
        "    callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=25, restore_best_weights=True),\n",
        "                 tfk.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\", factor=0.1, patience=20, min_lr=1e-5, mode='max')]\n",
        ").history"
      ],
      "metadata": {
        "id": "Tf_3vmZV6KA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eff_modelS.save('EffnetSmall_SMOTE_TL')"
      ],
      "metadata": {
        "id": "tkBxhzgH6LMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ft_modelS = tfk.models.load_model('EffnetSmall_SMOTE_TL')"
      ],
      "metadata": {
        "id": "F0TAHZlI6MjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#In the way efficient net works, we need not to unfreeze the batch normalization layers\n",
        "ft_modelS.get_layer('efficientnetv2-s').trainable = True\n",
        "for i, layer in enumerate(ft_modelS.get_layer('efficientnetv2-s').layers):\n",
        "  if 'bn' in layer.name:\n",
        "    layer.trainable=False\n",
        "  print(i, layer.name, layer.trainable)"
      ],
      "metadata": {
        "id": "GY_PxQ1X6Odc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We decided to freeze up to the 200-th layer\n",
        "N = 200\n",
        "for i, layer in enumerate(ft_modelS.get_layer('efficientnetv2-s').layers[:N]):\n",
        "  layer.trainable=False\n",
        "for i, layer in enumerate(ft_modelS.get_layer('efficientnetv2-s').layers):\n",
        "   print(i, layer.name, layer.trainable)\n",
        "ft_modelS.summary()"
      ],
      "metadata": {
        "id": "VyTM76Ia6P1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ft_modelS.compile(loss=tfk.losses.CategoricalCrossentropy(),\\\n",
        "                  optimizer=tfk.optimizers.AdamW(1e-5,weight_decay=5e-5),\\\n",
        "                  metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "XkfKjfkA6RMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ftSmall_history = ft_modelS.fit(\n",
        "    x = X_train1*255,\n",
        "    y = y_train1,\n",
        "    batch_size = 32,\n",
        "    epochs = 1000,\n",
        "    validation_data = (X_val*255, y_val),\n",
        "    callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=25, restore_best_weights=True),\n",
        "                 tfk.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\", factor=0.1, patience=20, min_lr=1e-6, mode='max')]\n",
        ").history"
      ],
      "metadata": {
        "id": "rmpsb7Ac6SiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ft_modelS.save('EffNetSmall_SMOTE_FT')"
      ],
      "metadata": {
        "id": "jutuxMiF6TgP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
