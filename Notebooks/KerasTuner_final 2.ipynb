{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkcO3iBa9HVV"
      },
      "source": [
        "#Connect to google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Phg81TdwyxQz",
        "outputId": "e10c090a-81b3-440f-e75c-40a6175fd094"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive/My Drive/[2023-2024] AN2DL/Homework 1\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/My Drive/[2023-2024] AN2DL/Homework 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O41sPDv_9LSp"
      },
      "source": [
        "#Import libraries and set parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSr037vty2AV"
      },
      "outputs": [],
      "source": [
        "# Fix randomness and hide warnings\n",
        "seed = 80\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "os.environ['MPLCONFIGDIR'] = os.getcwd()+'/configs/'\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=Warning)\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(seed)\n",
        "\n",
        "import logging\n",
        "\n",
        "import random\n",
        "random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiVXqqbBzAz_",
        "outputId": "dff711e0-0ffa-4580-8e80-2b27293d62c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.14.0\n"
          ]
        }
      ],
      "source": [
        "# Import tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras as tfk\n",
        "from tensorflow.keras import layers as tfkl\n",
        "tf.autograph.set_verbosity(0)\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0KuLBkTzDGX"
      },
      "outputs": [],
      "source": [
        "# Import other libraries\n",
        "#library for computer vision\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgPL6g0u9TA5"
      },
      "source": [
        "#Data upload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y56J08kTzJeI",
        "outputId": "73501e8b-531f-4008-a8b3-62063e2e242f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5200, 96, 96, 3)\n",
            "(5200,)\n"
          ]
        }
      ],
      "source": [
        "data=np.load('public_data.npz', allow_pickle=True)\n",
        "images_not_normalized = data['data']\n",
        "labels_strings= data['labels']\n",
        "label_map = {\"healthy\": 0, \"unhealthy\": 1}\n",
        "labels = np.vectorize(label_map.get)(labels_strings)\n",
        "print(images_not_normalized.shape)\n",
        "print(labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzSaBU-l9XJO"
      },
      "source": [
        "#Normalization and cleaning of data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhm-83cJzLcN",
        "outputId": "55c1074d-b3d2-4e64-910b-9c2e8d76a740"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[[0.25490198 0.42745098 0.11764706]\n",
            "  [0.30588236 0.49019608 0.17254902]\n",
            "  [0.33333334 0.54901963 0.19215687]\n",
            "  ...\n",
            "  [0.25882354 0.48235294 0.17254902]\n",
            "  [0.23921569 0.4627451  0.15294118]\n",
            "  [0.20392157 0.42745098 0.11764706]]\n",
            "\n",
            " [[0.3019608  0.4745098  0.16470589]\n",
            "  [0.32941177 0.5137255  0.19607843]\n",
            "  [0.30980393 0.5294118  0.17254902]\n",
            "  ...\n",
            "  [0.27058825 0.49411765 0.19215687]\n",
            "  [0.23921569 0.4627451  0.16078432]\n",
            "  [0.20392157 0.42745098 0.1254902 ]]\n",
            "\n",
            " [[0.31764707 0.5176471  0.20784314]\n",
            "  [0.31764707 0.52156866 0.2       ]\n",
            "  [0.3137255  0.5411765  0.20784314]\n",
            "  ...\n",
            "  [0.36078432 0.5686275  0.3019608 ]\n",
            "  [0.29803923 0.5058824  0.23921569]\n",
            "  [0.26666668 0.4745098  0.20784314]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.1254902  0.26666668 0.07843138]\n",
            "  [0.14117648 0.2901961  0.09019608]\n",
            "  [0.21960784 0.3882353  0.16862746]\n",
            "  ...\n",
            "  [0.7647059  0.92156863 0.6745098 ]\n",
            "  [0.7372549  0.89411765 0.65882355]\n",
            "  [0.7254902  0.88235295 0.64705884]]\n",
            "\n",
            " [[0.07843138 0.21960784 0.03137255]\n",
            "  [0.11764706 0.26666668 0.06666667]\n",
            "  [0.14509805 0.3137255  0.09411765]\n",
            "  ...\n",
            "  [0.8117647  0.96862745 0.73333335]\n",
            "  [0.7647059  0.91764706 0.69411767]\n",
            "  [0.7490196  0.9019608  0.6862745 ]]\n",
            "\n",
            " [[0.08235294 0.22352941 0.03529412]\n",
            "  [0.09803922 0.24705882 0.04705882]\n",
            "  [0.14117648 0.30980393 0.09019608]\n",
            "  ...\n",
            "  [0.69803923 0.8509804  0.627451  ]\n",
            "  [0.7294118  0.88235295 0.6666667 ]\n",
            "  [0.72156864 0.8745098  0.65882355]]]\n"
          ]
        }
      ],
      "source": [
        "#Normalize images\n",
        "images=[]\n",
        "for img in images_not_normalized:\n",
        "  img=(img/255).astype(np.float32)\n",
        "  images.append(img)\n",
        "\n",
        "images= np.array(images)\n",
        "print(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvDbl2eUzONj",
        "outputId": "b12971c9-7749-43e9-d6b4-6693597db888"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(195,)\n",
            "(5005, 96, 96, 3)\n"
          ]
        }
      ],
      "source": [
        "#DATASET CLEANING!\n",
        "indices= np.array([ 58, 95, 137, 138, 171, 207, 338,  412, 434, 486, 506, 529, 571, 599, 622, 658, 692, 701, 723, 725, 753, 779, 783, 827, 840, 880, 898, 901, 961, 971, 974, 989,\n",
        " 1028, 1044, 1064, 1065, 1101, 1149, 1172, 1190, 1191, 1265, 1268, 1280, 1333, 1384, 1443, 1466, 1483, 1528, 1541, 1554, 1594, 1609, 1630, 1651, 1690, 1697, 1752, 1757, 1759,\n",
        " 1806, 1828, 1866, 1903, 1938, 1939, 1977, 1981, 1988, 2022, 2081, 2090, 2150, 2191, 2192, 2198, 2261, 2311, 2328, 2348, 2380, 2426, 2435, 2451, 2453, 2487, 2496, 2515, 2564, 2581,\n",
        " 2593, 2596, 2663, 2665, 2676, 2727, 2734, 2736, 2755, 2779, 2796, 2800, 2830, 2831, 2839, 2864, 2866, 2889, 2913, 2929, 2937, 3033, 3049, 3055, 3086, 3105, 3108, 3144, 3155, 3286,\n",
        " 3376, 3410, 3436, 3451, 3488, 3490, 3572, 3583, 3666, 3688, 3700, 3740, 3770, 3800, 3801, 3802, 3806, 3811, 3821, 3835, 3862, 3885, 3896, 3899, 3904, 3927, 3931, 3946, 3950, 3964,\n",
        " 3988, 3989, 4049, 4055, 4097, 4100, 4118, 4144, 4150, 4282, 4310, 4314, 4316, 4368, 4411, 4475, 4476, 4503, 4507, 4557, 4605, 4618, 4694, 4719, 4735, 4740, 4766, 4779, 4837, 4848,\n",
        " 4857, 4860, 4883, 4897, 4903, 4907, 4927, 5048, 5080, 5082, 5121, 5143, 5165, 5171])\n",
        "print(indices.shape)\n",
        "mask = np.ones(len(images), dtype=bool)\n",
        "mask[indices]=False\n",
        "images = images[mask]\n",
        "labels = labels[mask]\n",
        "print(images.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Split dataset"
      ],
      "metadata": {
        "id": "R9XJcq_mMQTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = tfk.utils.to_categorical(labels,len(np.unique(labels))) #one hot encoding"
      ],
      "metadata": {
        "id": "tj2kkDk8K3vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9r0NJwv0JI3",
        "outputId": "63c45286-67d2-41ab-846f-c93dba86cbd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3753 1252\n"
          ]
        }
      ],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(images, labels, random_state=seed, test_size=.25, stratify=labels)\n",
        "print(X_train.shape[0], X_val.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zm8OofEo6eL7"
      },
      "outputs": [],
      "source": [
        "input_shape = X_train.shape[1:]\n",
        "output_shape = y_train.shape[1:]\n",
        "batch_size = 32\n",
        "epochs = 100\n",
        "\n",
        "# Print input shape, batch size, and number of epochs\n",
        "print(f\"Input Shape: {input_shape}, Output Shape: {output_shape}, Batch Size: {batch_size}, Epochs: {epochs}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data augmentation"
      ],
      "metadata": {
        "id": "5d80PZJfMUD-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbgX5hfV0VfR"
      },
      "outputs": [],
      "source": [
        "%pip install keras_cv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_cv"
      ],
      "metadata": {
        "id": "dkKuxg1iLH3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cutmix = keras_cv.layers.CutMix(10)\n",
        "output = cutmix({\"images\": X_train, \"labels\": y_train})"
      ],
      "metadata": {
        "id": "ELOKL4t6LKDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mixup = keras_cv.layers.MixUp(10)\n",
        "output_mixup = mixup({\"images\":X_train, \"labels\": y_train})"
      ],
      "metadata": {
        "id": "qCg0V2FpLL4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_cutmix_mixup = mixup({\"images\":output[\"images\"], \"labels\": output[\"labels\"]})"
      ],
      "metadata": {
        "id": "3aSl7-ZpLNxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_cutmix = output[\"images\"]\n",
        "x_train_mixup = output_mixup[\"images\"]\n",
        "x_train_cutmixup = output_cutmix_mixup[\"images\"]\n",
        "\n",
        "y_train_cutmix = output[\"labels\"]\n",
        "y_train_mixup = output_mixup[\"labels\"]\n",
        "y_train_cutmixup = output_cutmix_mixup[\"labels\"]"
      ],
      "metadata": {
        "id": "jTwCx-jcLP8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.concatenate((X_train, x_train_cutmix, x_train_mixup, x_train_cutmixup), axis = 0)"
      ],
      "metadata": {
        "id": "DKIfZEAkLRyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.concatenate((y_train, y_train_cutmix, y_train_mixup, y_train_cutmixup), axis = 0)"
      ],
      "metadata": {
        "id": "Gfbm1UpALT4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del x_train_cutmix\n",
        "del x_train_mixup\n",
        "del x_train_cutmixup"
      ],
      "metadata": {
        "id": "4gLBa7pNLXue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del y_train_cutmix\n",
        "del y_train_mixup\n",
        "del y_train_cutmixup"
      ],
      "metadata": {
        "id": "xpCgC31vLZSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del output\n",
        "del output_mixup\n",
        "del output_cutmix_mixup"
      ],
      "metadata": {
        "id": "x_1t9-b6LbPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The function will distribute the samples uniformly over dataset\n",
        "def unison_shuffled_copies(a, b):\n",
        "    assert len(a) == len(b)\n",
        "    p = np.random.permutation(len(a))\n",
        "    return a[p], b[p]"
      ],
      "metadata": {
        "id": "2uq3Iq6GLdD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_augmented_shuffled, y_train_augmented_shuffled = unison_shuffled_copies(X_train, y_train)"
      ],
      "metadata": {
        "id": "Z2JlziEULe2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_0sq63wlkf5"
      },
      "source": [
        "#Transfer Learning on MobileNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f26pOvaYk2Cp"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.mobilenet import preprocess_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8Pf4Gywk2ib"
      },
      "outputs": [],
      "source": [
        "mobile = tfk.applications.MobileNetV2(\n",
        "    input_shape=(96, 96, 3),\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    pooling='avg',\n",
        ")\n",
        "tfk.utils.plot_model(mobile, show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZP0X8ualpLG"
      },
      "source": [
        "Install Keras Tuner to do hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvBeqDn7k4f-"
      },
      "outputs": [],
      "source": [
        "!pip install keras-tuner -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJXNGBMCk7Rk"
      },
      "outputs": [],
      "source": [
        "# Use the supernet as feature extractor, i.e. freeze all its weigths\n",
        "import keras_tuner\n",
        "def build_model(hp):\n",
        "  mobile.trainable = False\n",
        "  tf.random.set_seed(seed)\n",
        "\n",
        "  preprocessing = tf.keras.Sequential([ #a layer that (in fact is composed by multiples) applies the augmentation\n",
        "      tfkl.RandomFlip(\"vertical\"),\n",
        "      tfkl.RandomFlip(\"horizontal\"),\n",
        "      tfkl.RandomRotation(0.5),\n",
        "      tfkl.RandomZoom(0.3)\n",
        "  ], name='preprocessing')\n",
        "\n",
        "  # Create an input layer with shape (96, 96, 3)\n",
        "  inputs = tfk.Input(shape=(96, 96, 3))\n",
        "  # Connect MobileNetV2 to the input\n",
        "  preprocessing = preprocessing(inputs) #perform augmentation, then connect to the same architectures\n",
        "  x = mobile(preprocessing)\n",
        "  #We put for both the dense layers, the parameter hp.Int representing the function Int of hp thanks to which we will do hyperparameter search through the values defined with a specific step\n",
        "  x = tfkl.Dense(hp.Int('units', min_value = 128, max_value = 256, step = 64), kernel_initializer=tfk.initializers.HeUniform(seed=seed), name='HiddenDense1')(x)\n",
        "  x = tfkl.Activation('relu', name='HiddenActivation1')(x)\n",
        "  x = tfkl.BatchNormalization()(x)\n",
        "  x = tfkl.Dense(hp.Int('units', min_value = 128, max_value = 256, step = 64), kernel_initializer=tfk.initializers.HeUniform(seed=seed), name='HiddenDense2')(x)\n",
        "  x = tfkl.Activation('relu', name='HiddenActivation2')(x)\n",
        "  x = tfkl.BatchNormalization()(x)\n",
        "\n",
        "  # Add a Dense layer with 2 units and softmax activation as the classifier\n",
        "  outputs = tfkl.Dense(2, activation='softmax')(x)\n",
        "\n",
        "  # Create a Model connecting input and output\n",
        "  tl_model = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n",
        "\n",
        "  # Compile the model with Categorical Cross-Entropy loss and Adam optimizer\n",
        "  tl_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.AdamW(1e-4,weight_decay=5e-4), metrics=['accuracy'])\n",
        "\n",
        "  # Display model summary\n",
        "  tl_model.summary()\n",
        "  return tl_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgFCDDO2lBys"
      },
      "outputs": [],
      "source": [
        "tuner = keras_tuner.RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=5,\n",
        "    executions_per_trial=3\n",
        ")#We create the object tuner, defining the parameter of the hyperparameter search, specifying that for each parameter value we want 3 executions, with a max of 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYUlB_SMlGxz"
      },
      "outputs": [],
      "source": [
        "tuner.search(\n",
        "    X_train_augmented_shuffled,\n",
        "    y_train_augmented_shuffled,\n",
        "    epochs = 150,\n",
        "    validation_data = (X_val, y_val))#We start the search"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
